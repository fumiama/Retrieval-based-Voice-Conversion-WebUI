{
    "### Model comparison\n> You can get model ID (long) from `View model information` below.\n\nCalculate a similarity between two models.": "### Model comparison\n> You can get model ID (long) from `View model information` below.\n\nCalculate a similarity between two models.",
    "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.": "### Создание модели из данных\n> Полученных в процессе обучения (введите путь к большому файлу модели в папке 'logs').\n\nМожет пригодиться, если вам нужно завершить обучение и получить маленький файл готовой модели, или если вам нужно проверить недообученную модель.",
    "### Model fusion\nCan be used to test timbre fusion.": "### Слияние моделей> Может быть использовано для проверки слияния тембра.",
    "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Изменить информацию о модели\n> Работает только с маленькими моделями, взятыми из папки 'weights'.",
    "### Step 1. Fill in the experimental configuration.\nExperimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.": "### Шаг 1. Конфигурирование модели.\nДанные обучения модели сохраняются в папку 'logs', и для каждой модели создаётся отдельная папка. Введите вручную путь к настройкам для модели, в которой находятся логи и тренировочные файлы.",
    "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.": "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.",
    "### Step 3. Start training.\nFill in the training settings and start training the model and index.": "### Step 3. Start training.\nFill in the training settings and start training the model and index.",
    "### View model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Просмотреть информацию о модели\n> Работает только с маленькими моделями, взятыми из папки 'weights'.",
    "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).": "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).",
    "Actually calculated": "Actually calculated",
    "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume": "Использовать громкость входного файла для замены или перемешивания с громкостью выходного файла. Чем ближе соотношение к 1, тем больше используется звука из выходного файла:",
    "Algorithmic delays (ms)": "Algorithmic delays (ms)",
    "All processes have been completed!": "Все процессы завершены!",
    "Audio device": "Аудиоустройство",
    "Auto-detect index path and select from the dropdown": "Автоматически найденные файлы индексов черт (выберите вариант из списка):",
    "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').": "Массовое преобразование. Введите путь к папке, в которой находятся файлы для преобразования голоса или выгрузите несколько аудиофайлов. Сконвертированные файлы будут сохранены в указанной папке (по умолчанию: 'opt').",
    "Batch inference": "Batch inference",
    "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.": "Пакетная обработка для разделения вокального сопровождения с использованием модели UVR5.<br>Пример допустимого формата пути к папке: D:\\path\\to\\input\\folder<br> Модель разделена на три категории:<br>1. Сохранить вокал: выберите этот вариант для звука без гармоний. Он сохраняет вокал лучше, чем HP5. Он включает в себя две встроенные модели: HP2 и HP3. HP3 может немного пропускать инструментал, но сохраняет вокал немного лучше, чем HP2.<br>2. Сохранить только основной вокал: выберите этот вариант для звука с гармониями. Это может ослабить основной вокал. Он включает одну встроенную модель: HP5.<br>3. Модели удаления реверберации и задержки (от FoxJoy):<br>  (1) MDX-Net: лучший выбор для удаления стереореверберации, но он не может удалить монореверберацию;<br>&emsp;(234) DeEcho: удаляет эффекты задержки. Агрессивный режим удаляет более тщательно, чем Нормальный режим. DeReverb дополнительно удаляет реверберацию и может удалять монореверберацию, но не очень эффективно для сильно реверберированного высокочастотного контента.<br>Примечания по удалению реверберации/задержки:<br>1. Время обработки для модели DeEcho-DeReverb примерно в два раза больше, чем для двух других моделей DeEcho.<br>2. Модель MDX-Net-Dereverb довольно медленная.<br>3. Рекомендуемая самая чистая конфигурация — сначала применить MDX-Net, а затем DeEcho-Aggressive.",
    "Batch size per GPU": "Размер пачки для GPU:",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "Кэшировать все тренировочные сеты в видеопамять. Кэширование маленький датасетов (меньше 10 минут) может ускорить тренировку, но кэширование больших, наоборот, займёт много видеопамяти и не сильно ускорит тренировку:",
    "Calculate": "Calculate",
    "Choose sample rate of the device": "Choose sample rate of the device",
    "Choose sample rate of the model": "Choose sample rate of the model",
    "Convert": "Преобразовать",
    "Device type": "Device type",
    "Enable phase vocoder": "Enable phase vocoder",
    "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2": "Введите, какие(-ую) GPU(-у) хотите использовать через '-', например 0-1-2, чтобы использовать GPU с номерами 0, 1 и 2:",
    "Enter the experiment name": "Название модели:",
    "Enter the path of the audio folder to be processed": "Путь к папке с аудиофайлами для обработки:",
    "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)": "Путь к папке с аудиофайлами для переработки (можно скопировать путь из адресной строки файлового менеджера):",
    "Enter the path of the training folder": "Путь к папке с аудиозаписями, на которых будет обучаться модель:",
    "Exist": "Exist",
    "Export Onnx": "Экспорт ONNX",
    "Export Onnx Model": "Экспортировать модель",
    "Export audio (click on the three dots in the lower right corner to download)": "Аудиофайл (чтобы скачать, нажмите на три точки справа в плеере)",
    "Export file format": "Формат выходных файлов",
    "Extra inference time": "Доп. время переработки",
    "Extract": "Создать модель",
    "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation": "Файл дуги F0 (не обязательно). Одна тональность на каждую строчку. Заменяет обычный F0 и модуляцию тональности:",
    "FAQ (Frequently Asked Questions)": "ЧаВо (часто задаваемые вопросы)",
    "Fade length": "Длина затухания",
    "Fail": "失败",
    "Feature extraction": "Извлечь черты",
    "Feature searching ratio": "Соотношение поиска черт:",
    "Formant offset": "共振偏移",
    "Fusion": "Запустить слияние",
    "GPU Information": "Информация о графических процессорах (GPUs):",
    "General settings": "Основные настройки",
    "Hidden": "Hidden",
    "ID of model A (long)": "ID of model A (long)",
    "ID of model B (long)": "ID of model B (long)",
    "ID(long)": "ID (long)",
    "ID(short)": "ID (short)",
    "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.": "Если значение больше 3: применить медианную фильтрацию к вытащенным тональностям. Значение контролирует радиус фильтра и может уменьшить излишнее дыхание.",
    "Inference time (ms)": "Время переработки (мс)",
    "Inferencing voice": "Желаемый голос:",
    "Information": "Information",
    "Input device": "Входное устройство",
    "Input noise reduction": "Уменьшение входного шума",
    "Input voice monitor": "Input voice monitor",
    "Link index to outside folder": "Link index to outside folder",
    "Load model": "Загрузить модель",
    "Load pre-trained base model D path": "Путь к предварительно обученной базовой модели D:",
    "Load pre-trained base model G path": "Путь к предварительно обученной базовой модели G:",
    "Loudness factor": "коэффициент громкости",
    "Model": "Модели",
    "Model Author": "Model Author",
    "Model Author (Nullable)": "Model Author (Nullable)",
    "Model Inference": "Изменение голоса",
    "Model architecture version": "Версия архитектуры модели:",
    "Model info": "Model info",
    "Model information to be modified": "Информация, которая будет изменена:",
    "Model information to be placed": "Информация о модели:",
    "Model name": "Model name",
    "Modify": "Изменить",
    "Multiple audio files can also be imported. If a folder path exists, this input is ignored.": "Можно также импортировать несколько аудиофайлов. Если путь к папке существует, то этот ввод игнорируется.",
    "No": "Нет",
    "None": "None",
    "Not exist": "Not exist",
    "Number of CPU processes used for harvest pitch algorithm": "Количество процессор harvest",
    "Number of CPU processes used for pitch extraction and data processing": "Число процессов ЦП, используемое для оценки высоты голоса и обработки данных:",
    "One-click training": "Обучение в одно нажатие",
    "Onnx Export Path": "Путь для сохранения модели в формате ONNX:",
    "Output converted voice": "Output converted voice",
    "Output device": "Выходное устройство",
    "Output information": "Статистика",
    "Output noise reduction": "Уменьшение выходного шума",
    "Path to Model": "Путь к папке:",
    "Path to Model A": "Путь к модели А:",
    "Path to Model B": "Путь к модели Б:",
    "Path to the feature index file. Leave blank to use the selected result from the dropdown": "Путь к файлу индекса черт. Оставьте пустым, чтобы использовать выбранный вариант из списка ниже:",
    "Performance settings": "Настройки быстроты",
    "Pitch detection algorithm": "Алгоритм оценки высоты звука",
    "Pitch guidance (f0)": "Pitch guidance (f0)",
    "Pitch settings": "Настройка высоты звука",
    "Please choose the .index file": "Пожалуйста, выберите файл индекса",
    "Please choose the .pth file": "Пожалуйста, выберите файл pth",
    "Please specify the speaker/singer ID": "Номер говорящего/поющего:",
    "Process data": "Обработать данные",
    "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy": "Защитить глухие согласные и звуки дыхания для предотвращения артефактов, например, разрывания в электронной музыке. Поставьте на 0.5, чтобы выключить. Уменьшите значение для повышения защиты, но учтите, что при этом может ухудшиться точность индексирования:",
    "RVC Model Path": "Путь к модели RVC:",
    "Read from model": "Read from model",
    "Refresh voice list and index path": "Обновить список голосов и индексов",
    "Reload device list": "Обновить список устройств",
    "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling": "Изменить частоту дискретизации в выходном файле на финальную. Поставьте 0, чтобы ничего не изменялось:",
    "Response threshold": "Порог ответа",
    "Sample length": "Длина сэмпла",
    "Sampling rate": "Sampling rate",
    "Save a small final model to the 'weights' folder at each save point": "Сохранять маленькую финальную модель в папку 'weights' на каждой точке сохранения:",
    "Save file name (default: same as the source file)": "Название сохранённого файла (по умолчанию: такое же, как и у входного):",
    "Save frequency (save_every_epoch)": "Частота сохранения (save_every_epoch):",
    "Save name": "Имя файла для сохранения:",
    "Save only the latest '.ckpt' file to save disk space": "Сохранять только последний файл '.ckpt', чтобы сохранить место на диске:",
    "Saved model name (without extension)": "Имя файла модели для сохранения (без расширения):",
    "Sealing date": "Sealing date",
    "Select Speaker/Singer ID": "Номер говорящего:",
    "Select the .index file": "Выбрать файл .index",
    "Select the .pth file": "Выбрать файл .pth",
    "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement": "Выберите алгоритм оценки высоты голоса ('pm': работает быстро, но даёт низкое качество речи; 'harvest': басы лучше, но работает очень медленно; 'crepe': лучшее качество, но сильно нагружает GPU; 'rmvpe': лучшее качество и минимальная нагрузка на GPU):",
    "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU": "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU",
    "Similarity": "Similarity",
    "Similarity (from 0 to 1)": "Similarity (from 0 to 1)",
    "Single inference": "Single inference",
    "Specify output folder": "Папка для результатов:",
    "Specify the output folder for accompaniment": "Путь к папке для сохранения аккомпанемента:",
    "Specify the output folder for vocals": "Путь к папке для сохранения вокала:",
    "Start audio conversion": "Начать конвертацию аудио",
    "Step 1: Processing data": "Шаг 1. Переработка данных",
    "Step 3a: Model training started": "Шаг 3. Запуск обучения модели",
    "Stop audio conversion": "Закончить конвертацию аудио",
    "Successfully built index into": "Successfully built index into",
    "Takeover WASAPI device": "Takeover WASAPI device",
    "Target sample rate": "Частота дискретизации аудио:",
    "The audio file to be processed": "The audio file to be processed",
    "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.": "Это программное обеспечение с открытым исходным кодом распространяется по лицензии MIT. Автор никак не контролирует это программное обеспечение. Пользователи, которые используют эту программу и распространяют аудиозаписи, полученные с помощью этой программы, несут полную ответственность за это. Если вы не согласны с этим, вы не можете использовать какие-либо коды и файлы в рамках этой программы или ссылаться на них. Подробнее в файле <b>Agreement-LICENSE.txt</b> в корневом каталоге программы.",
    "Total training epochs (total_epoch)": "Полное количество эпох (total_epoch):",
    "Train": "Обучение модели",
    "Train feature index": "Обучить индекс черт",
    "Train model": "Обучить модель",
    "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.": "Обучение модели завершено. Журнал обучения можно просмотреть в консоли или в файле 'train.log' в папке с моделью.",
    "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)": "Изменить высоту голоса (укажите количество полутонов; чтобы поднять голос на октаву, выберите 12, понизить на октаву — -12):",
    "Unfortunately, there is no compatible GPU available to support your training.": "К сожалению, у вас нету графического процессора, который поддерживает обучение моделей.",
    "Unknown": "Unknown",
    "Unload model to save GPU memory": "Выгрузить модель из памяти GPU для освобождения ресурсов",
    "Version": "Версия архитектуры модели:",
    "View": "Просмотреть информацию",
    "Vocals/Accompaniment Separation & Reverberation Removal": "Разделение вокала/аккомпанемента и удаление эхо",
    "Weight (w) for Model A": "Весы (w) модели А:",
    "Whether the model has pitch guidance": "Поддерживает ли модель изменение высоты голоса (1: да, 0: нет):",
    "Whether the model has pitch guidance (1: yes, 0: no)": "Поддерживает ли модель изменение высоты голоса (1: да, 0: нет):",
    "Whether the model has pitch guidance (required for singing, optional for speech)": "Поддержка изменения высоты звука (обязательно для пения, необязательно для речи):",
    "Yes": "Да",
    "ckpt Processing": "Обработка ckpt",
    "index path cannot contain unicode characters": "Путь к файлу индекса",
    "pth path cannot contain unicode characters": "Путь к файлу pth",
    "step2:Pitch extraction & feature extraction": "step2:Pitch extraction & feature extraction"
}
