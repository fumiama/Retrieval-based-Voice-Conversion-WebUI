{
    "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.": "### 모델 추출\n> logs 폴더 아래의 큰 파일 모델 경로 입력\n\n훈련 중간에 중단한 모델의 자동 추출 및 소형 파일 모델 저장이 안 되거나 중간 모델을 테스트하고 싶은 경우에 적합",
    "### Model fusion\nCan be used to test timbre fusion.": "### Model fusion\nCan be used to test timbre fusion.",
    "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.": "### 모델 정보 수정\n> 오직 weights 폴더 아래에서 추출된 작은 모델 파일만 지원",
    "### Step 1. Fill in the experimental configuration.\nExperimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.": "### Step 1. Fill in the experimental configuration.\nExperimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.",
    "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.": "### 第二步 音频处理\n#### 1. 音频切片\n自动遍历训练文件夹下所有可解码成音频的文件并进行切片归一化, 在实验目录下生成2个wav文件夹; 暂时只支持单人训练.",
    "### Step 3. Start training.\nFill in the training settings and start training the model and index.": "### 第三步 开始训练\n填写训练设置, 开始训练模型和索引.",
    "### View model information\n> Only supported for small model files extracted from the 'weights' folder.": "### 모델 정보 보기\n> 오직 weights 폴더에서 추출된 소형 모델 파일만 지원",
    "### 模型比较\n> 模型ID(长)请于下方`查看模型信息`中获得\n\n可用于比较两模型推理相似度": "### 模型比较\n> 模型ID(长)请于下方`查看模型信息`中获得\n\n可用于比较两模型推理相似度",
    "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).": "#### 2. 特征提取\n使用CPU提取音高(如果模型带音高), 使用GPU提取特征(选择卡号).",
    "Actually calculated": "实际计算",
    "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume": "입력 소스 볼륨 엔벨로프와 출력 볼륨 엔벨로프의 결합 비율 입력, 1에 가까울수록 출력 엔벨로프 사용",
    "Algorithmic delays (ms)": "알고리즘 지연(ms)",
    "All processes have been completed!": "전체 과정 완료!",
    "Audio device": "오디오 장치",
    "Auto-detect index path and select from the dropdown": "자동으로 index 경로 감지, 드롭다운 선택(dropdown)",
    "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').": "일괄 변환, 변환할 오디오 파일 폴더 입력 또는 여러 오디오 파일 업로드, 지정된 폴더(기본값 opt)에 변환된 오디오 출력.",
    "Batch inference": "일괄 추론",
    "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.": "인간 목소리와 반주 분리 배치 처리, UVR5 모델 사용. <br>적절한 폴더 경로 예시: E:\\codes\\py39\\vits_vc_gpu\\白鹭霜华测试样例(파일 관리자 주소 표시줄에서 복사하면 됨). <br>모델은 세 가지 유형으로 나뉨: <br>1. 인간 목소리 보존: 화음이 없는 오디오에 이것을 선택, HP5보다 주된 인간 목소리 보존에 더 좋음. 내장된 HP2와 HP3 두 모델, HP3는 약간의 반주 누락 가능성이 있지만 HP2보다 주된 인간 목소리 보존이 약간 더 좋음; <br>2. 주된 인간 목소리만 보존: 화음이 있는 오디오에 이것을 선택, 주된 인간 목소리에 약간의 약화 가능성 있음. 내장된 HP5 모델 하나; <br>3. 혼효음 제거, 지연 제거 모델(by FoxJoy):<br>  (1)MDX-Net(onnx_dereverb): 이중 채널 혼효음에는 최선의 선택, 단일 채널 혼효음은 제거할 수 없음;<br>&emsp;(234)DeEcho: 지연 제거 효과. Aggressive는 Normal보다 더 철저하게 제거, DeReverb는 추가로 혼효음을 제거, 단일 채널 혼효음은 제거 가능하지만 고주파 중심의 판 혼효음은 완전히 제거하기 어려움.<br>혼효음/지연 제거, 부록: <br>1. DeEcho-DeReverb 모델의 처리 시간은 다른 두 개의 DeEcho 모델의 거의 2배임;<br>2. MDX-Net-Dereverb 모델은 상당히 느림;<br>3. 개인적으로 추천하는 가장 깨끗한 구성은 MDX-Net 다음에 DeEcho-Aggressive 사용.",
    "Batch size per GPU": "각 그래픽 카드의 batch_size",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "모든 훈련 세트를 VRAM에 캐시할지 여부. 10분 미만의 소량 데이터는 캐시하여 훈련 속도를 높일 수 있지만, 대량 데이터 캐시는 VRAM을 과부하시키고 속도를 크게 향상시키지 못함",
    "Calculate": "计算",
    "Choose sample rate of the device": "장치 샘플링 레이트 사용",
    "Choose sample rate of the model": "모델 샘플링 레이트 사용",
    "Convert": "변환",
    "Device type": "设备类型",
    "Enable phase vocoder": "위상 보코더 활성화",
    "Enter the GPU index(es) separated by '-', e.g., 0-0-1 to use 2 processes in GPU0 and 1 process in GPU1": "rmvpe 카드 번호 설정: -로 구분된 입력 사용 카드 번호, 예: 0-0-1은 카드 0에서 2개 프로세스, 카드 1에서 1개 프로세스 실행",
    "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2": "-로 구분하여 입력하는 카드 번호, 예: 0-1-2는 카드 0, 카드 1, 카드 2 사용",
    "Enter the experiment name": "실험명 입력",
    "Enter the path of the audio folder to be processed": "처리할 오디오 파일 폴더 경로 입력",
    "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)": "처리할 오디오 파일 폴더 경로 입력(파일 탐색기 주소 표시줄에서 복사)",
    "Enter the path of the training folder": "훈련 파일 폴더 경로 입력",
    "Exist": "有",
    "Export Onnx": "Onnx 내보내기",
    "Export Onnx Model": "Onnx 모델 내보내기",
    "Export audio (click on the three dots in the lower right corner to download)": "출력 오디오(오른쪽 하단 세 개의 점, 클릭하면 다운로드 가능)",
    "Export file format": "내보낼 파일 형식",
    "Extra inference time": "추가 추론 시간",
    "Extract": "추출",
    "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation": "F0 곡선 파일, 선택적, 한 줄에 하나의 피치, 기본 F0 및 음높이 조절 대체",
    "FAQ (Frequently Asked Questions)": "자주 묻는 질문",
    "Fade length": "페이드 인/아웃 길이",
    "Fail": "失败",
    "Feature extraction": "특징 추출",
    "Formant offset": "共振偏移",
    "Fusion": "융합",
    "GPU Information": "그래픽 카드 정보",
    "General settings": "일반 설정",
    "Hidden": "不显示",
    "ID of model A (long)": "A模型ID(长)",
    "ID of model B (long)": "B模型ID(长)",
    "ID(long)": "ID(long)",
    "ID(short)": "ID(短)",
    "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.": ">=3인 경우 harvest 피치 인식 결과에 중간값 필터 적용, 필터 반경은 값으로 지정, 사용 시 무성음 감소 가능",
    "Inference time (ms)": "추론 시간 (ms)",
    "Inferencing voice": "추론 음색",
    "Information": "정보",
    "Input device": "입력 장치",
    "Input noise reduction": "입력 노이즈 감소",
    "Input voice monitor": "입력 모니터링",
    "Link index to outside folder": "链接索引到外部",
    "Load model": "모델 로드",
    "Load pre-trained base model D path": "미리 훈련된 베이스 모델 D 경로 로드",
    "Load pre-trained base model G path": "미리 훈련된 베이스 모델 G 경로 로드",
    "Loudness factor": "음량 인자",
    "Model": "모델",
    "Model Author": "模型作者",
    "Model Author (Nullable)": "模型作者(可空)",
    "Model Inference": "모델 추론",
    "Model architecture version": "모델 버전 및 모델",
    "Model info": "모델 정보",
    "Model information to be modified": "변경할 모델 정보",
    "Model information to be placed": "삽입할 모델 정보",
    "Model name": "模型名",
    "Modify": "수정",
    "Multiple audio files can also be imported. If a folder path exists, this input is ignored.": "여러 오디오 파일을 일괄 입력할 수도 있음, 둘 중 하나 선택, 폴더 우선 읽기",
    "No": "아니오",
    "None": "None",
    "Not exist": "无",
    "Number of CPU processes used for harvest pitch algorithm": "harvest 프로세스 수",
    "Number of CPU processes used for pitch extraction and data processing": "음높이 추출 및 데이터 처리에 사용되는 CPU 프로세스 수",
    "One-click training": "원클릭 훈련",
    "Onnx Export Path": "Onnx 출력 경로",
    "Output converted voice": "출력 음성 변조",
    "Output device": "출력 장치",
    "Output information": "출력 정보",
    "Output noise reduction": "출력 노이즈 감소",
    "Path to Model": "모델 경로",
    "Path to Model A": "A 모델 경로",
    "Path to Model B": "B 모델 경로",
    "Path to the feature index file. Leave blank to use the selected result from the dropdown": "특징 검색 라이브러리 파일 경로, 비어 있으면 드롭다운 선택 결과 사용",
    "Performance settings": "성능 설정",
    "Pitch detection algorithm": "음높이 알고리즘",
    "Pitch guidance (f0)": "音高引导(f0)",
    "Pitch settings": "음조 설정",
    "Please choose the .index file": "index 파일 선택",
    "Please choose the .pth file": "pth 파일 선택",
    "Please specify the speaker/singer ID": "화자 ID 지정 필요",
    "Process data": "데이터 처리",
    "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy": "청자음과 호흡 소리를 보호, 전자음 찢김 등의 아티팩트 방지, 0.5까지 올려서 비활성화, 낮추면 보호 강도 증가하지만 인덱스 효과 감소 가능성 있음",
    "RVC Model Path": "RVC 모델 경로",
    "Read from model": "从模型中读取",
    "Refresh voice list and index path": "음색 목록 및 인덱스 경로 새로고침",
    "Reload device list": "장치 목록 재로드",
    "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling": "후처리 재샘플링을 최종 샘플링 레이트로, 0은 재샘플링하지 않음",
    "Response threshold": "응답 임계값",
    "Sample length": "샘플링 길이",
    "Sampling rate": "샘플링률",
    "Save a small final model to the 'weights' folder at each save point": "저장 시마다 최종 소형 모델을 weights 폴더에 저장할지 여부",
    "Save file name (default: same as the source file)": "저장될 파일명, 기본적으로 빈 공간은 원본 파일과 동일한 이름으로",
    "Save frequency (save_every_epoch)": "저장 빈도 save_every_epoch",
    "Save name": "저장 이름",
    "Save only the latest '.ckpt' file to save disk space": "디스크 공간을 절약하기 위해 최신 ckpt 파일만 저장할지 여부",
    "Saved model name (without extension)": "저장된 모델명은 접미사 없음",
    "Sealing date": "封装时间",
    "Search feature ratio (controls accent strength, too high has artifacting)": "검색 특징 비율",
    "Select Speaker/Singer ID": "화자 ID 선택",
    "Select the .index file": ".index 파일 선택",
    "Select the .pth file": ".pth 파일 선택",
    "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement": "음높이 추출 알고리즘 선택, 노래 입력 시 pm으로 속도 향상, harvest는 저음이 좋지만 매우 느림, crepe는 효과가 좋지만 GPU 사용, rmvpe는 효과가 가장 좋으며 GPU를 적게 사용",
    "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU": "음높이 추출 알고리즘 선택: 노래 입력 시 pm으로 속도 향상, 고품질 음성에는 CPU가 부족할 때 dio 사용, harvest는 품질이 더 좋지만 느림, rmvpe는 효과가 가장 좋으며 CPU/GPU를 적게 사용",
    "Similarity": "相似度",
    "Similarity (from 0 to 1)": "相似度(0到1)",
    "Single inference": "단일 추론",
    "Specify output folder": "출력 파일 폴더 지정",
    "Specify the output folder for accompaniment": "주된 목소리가 아닌 출력 폴더 지정",
    "Specify the output folder for vocals": "주된 목소리 출력 폴더 지정",
    "Start audio conversion": "오디오 변환 시작",
    "Step 1: Processing data": "step1: 데이터 처리 중",
    "Step 3a: Model training started": "step3a: 모델 훈련 중",
    "Stop audio conversion": "오디오 변환 중지",
    "Successfully built index into": "成功构建索引到",
    "Takeover WASAPI device": "独占 WASAPI 设备",
    "Target sample rate": "목표 샘플링률",
    "The audio file to be processed": "待处理音频文件",
    "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.": "이 소프트웨어는 MIT 라이선스로 공개되며, 저자는 소프트웨어에 대해 어떠한 통제권도 가지지 않습니다. 모든 귀책사유는 소프트웨어 사용자 및 소프트웨어에서 생성된 결과물을 사용하는 당사자에게 있습니다. <br>해당 조항을 인정하지 않는 경우, 소프트웨어 패키지의 어떠한 코드나 파일도 사용하거나 인용할 수 없습니다. 자세한 내용은 루트 디렉토리의 <b>LICENSE</b>를 참조하세요.",
    "Total training epochs (total_epoch)": "총 훈련 라운드 수 total_epoch",
    "Train": "훈련",
    "Train feature index": "특징 인덱스 훈련",
    "Train model": "모델 훈련",
    "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.": "훈련 완료, 콘솔 훈련 로그 또는 실험 폴더 내의 train.log 확인 가능",
    "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)": "키 변경(정수, 반음 수, 옥타브 상승 12, 옥타브 하강 -12)",
    "Unfortunately, there is no compatible GPU available to support your training.": "사용 가능한 그래픽 카드가 없어 훈련을 지원할 수 없습니다",
    "Unknown": "Unknown",
    "Unload model to save GPU memory": "음색 언로드로 디스플레이 메모리 절약",
    "Version": "버전",
    "View": "보기",
    "Vocals/Accompaniment Separation & Reverberation Removal": "반주 인간 목소리 분리 & 혼효음 제거 & 에코 제거",
    "Weight (w) for Model A": "A 모델 가중치",
    "Whether the model has pitch guidance": "모델이 음높이 지도를 포함하는지 여부",
    "Whether the model has pitch guidance (1: yes, 0: no)": "모델이 음높이 지도를 포함하는지 여부, 1은 예, 0은 아니오",
    "Whether the model has pitch guidance (required for singing, optional for speech)": "모델이 음높이 지도를 포함하는지 여부(노래에는 반드시 필요, 음성에는 필요 없음)",
    "Yes": "예",
    "ckpt Processing": "ckpt 처리",
    "index path cannot contain unicode characters": "index 파일 경로는 중국어를 포함할 수 없음",
    "pth path cannot contain unicode characters": "pth 파일 경로는 중국어를 포함할 수 없음",
    "step2:Pitch extraction & feature extraction": "step2: 음높이 추출 & 특징 추출 중",
    "模型作者": "模型作者"
}
