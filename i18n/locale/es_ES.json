{
    "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.": "### Extracción de modelo\n> Ingrese la ruta de un archivo de modelo grande en la carpeta 'logs'.\n\nAplicable cuando desea extraer un archivo de modelo pequeño después de entrenar a mitad de camino y no se guardó automáticamente, o cuando desea probar un modelo intermedio.",
    "### Model fusion\nCan be used to test timbre fusion.": "### Model fusion\nCan be used to test timbre fusion.",
    "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Modificar la información del modelo\n> Solo admite archivos de modelos pequeños extraídos en la carpeta 'weights'.",
    "### Step 1. Fill in the experimental configuration.\nExperimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.": "### Step 1. Fill in the experimental configuration.\nExperimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.",
    "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.": "### Paso dos: Procesamiento de audio\n#### 1. Segmentación de audio\nRecorre automáticamente todos los archivos que se pueden decodificar en audio en la carpeta de entrenamiento y realiza la segmentación y normalización, generando 2 carpetas wav en el directorio del experimento; por ahora solo se admite el entrenamiento individual.",
    "### Step 3. Start training.\nFill in the training settings and start training the model and index.": "### Paso tres: Comienza el entrenamiento\nCompleta la configuración de entrenamiento, comienza a entrenar el modelo y el índice.",
    "### View model information\n> Only supported for small model files extracted from the 'weights' folder.": "### Ver información del modelo\n> Solo aplicable a archivos de modelos pequeños extraídos de la carpeta 'weights'.",
    "### 模型比较\n> 模型ID(长)请于下方`查看模型信息`中获得\n\n可用于比较两模型推理相似度": "### 模型比较\n> 模型ID(长)请于下方`查看模型信息`中获得\n\n可用于比较两模型推理相似度",
    "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).": "#### 2. Extracción de características\nUtiliza la CPU para extraer el tono (si el modelo tiene tono), utiliza la GPU para extraer características (selecciona el número de tarjeta).",
    "Actually calculated": "Valor realmente calculado",
    "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume": "Proporción de fusión para reemplazar el sobre de volumen de entrada con el sobre de volumen de salida, cuanto más cerca de 1, más se utiliza el sobre de salida",
    "Algorithmic delays (ms)": "Retrasos algorítmicos (ms)",
    "All processes have been completed!": "¡Todo el proceso ha terminado!",
    "Audio device": "Dispositivo de audio",
    "Auto-detect index path and select from the dropdown": "Detección automática de la ruta del índice, selección desplegable (dropdown)",
    "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').": "Conversión por lotes, ingrese la carpeta que contiene los archivos de audio para convertir o cargue varios archivos de audio. El audio convertido se emitirá en la carpeta especificada (opción predeterminada).",
    "Batch inference": "Inferencia por lotes",
    "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.": "Procesamiento por lotes para la separación de acompañamiento vocal utilizando el modelo UVR5.<br>Ejemplo de formato de ruta de carpeta válido: D:\\ruta\\a\\la\\carpeta\\de\\entrada (copiar desde la barra de direcciones del administrador de archivos).<br>El modelo se divide en tres categorías:<br>1. Preservar voces: Elija esta opción para audio sin armonías. Preserva las voces mejor que HP5. Incluye dos modelos incorporados: HP2 y HP3. HP3 puede filtrar ligeramente el acompañamiento pero conserva las voces un poco mejor que HP2.<br>2. Preservar solo voces principales: Elija esta opción para audio con armonías. Puede debilitar las voces principales. Incluye un modelo incorporado: HP5.<br>3. Modelos de des-reverberación y des-retardo (por FoxJoy):<br>  (1) MDX-Net: La mejor opción para la eliminación de reverberación estéreo pero no puede eliminar la reverberación mono;<br>&emsp;(234) DeEcho: Elimina efectos de retardo. El modo Agresivo elimina más a fondo que el modo Normal. DeReverb adicionalmente elimina la reverberación y puede eliminar la reverberación mono, pero no muy efectivamente para contenido de alta frecuencia fuertemente reverberado.<br>Notas de des-reverberación/des-retardo:<br>1. El tiempo de procesamiento para el modelo DeEcho-DeReverb es aproximadamente el doble que los otros dos modelos DeEcho.<br>2. El modelo MDX-Net-Dereverb es bastante lento.<br>3. La configuración más limpia recomendada es aplicar primero MDX-Net y luego DeEcho-Agresivo.",
    "Batch size per GPU": "Tamaño del lote (batch_size) por tarjeta gráfica",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "Si almacenar en caché todos los conjuntos de entrenamiento en la memoria de la GPU. Los conjuntos de datos pequeños (menos de 10 minutos) se pueden almacenar en caché para acelerar el entrenamiento, pero el almacenamiento en caché de conjuntos de datos grandes puede causar errores de memoria en la GPU y no aumenta la velocidad de manera significativa.",
    "Calculate": "Calcularlo",
    "Choose sample rate of the device": "Elija la frecuencia de muestreo del dispositivo",
    "Choose sample rate of the model": "Elija la frecuencia de muestreo del modelo",
    "Convert": "Conversión",
    "Device type": "Tipo de dispositivo",
    "Enable phase vocoder": "Habilitar vocoder de fase",
    "Enter the GPU index(es) separated by '-', e.g., 0-0-1 to use 2 processes in GPU0 and 1 process in GPU1": "Separe los números de identificación de la GPU con '-' al ingresarlos. Por ejemplo, '0-1-2' significa usar GPU 0, GPU 1 y GPU 2.",
    "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2": "Separe los números de identificación de la GPU con '-' al ingresarlos. Por ejemplo, '0-1-2' significa usar GPU 0, GPU 1 y GPU 2.",
    "Enter the experiment name": "Ingrese el nombre del modelo",
    "Enter the path of the audio folder to be processed": "Ingrese la ruta a la carpeta de audio que se procesará",
    "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)": "Ingrese la ruta a la carpeta de audio que se procesará (simplemente cópiela desde la barra de direcciones del administrador de archivos)",
    "Enter the path of the training folder": "Introduzca la ruta de la carpeta de entrenamiento",
    "Exist": "Existente",
    "Export Onnx": "Exportar Onnx",
    "Export Onnx Model": "Exportar modelo Onnx",
    "Export audio (click on the three dots in the lower right corner to download)": "Salida de audio (haga clic en los tres puntos en la esquina inferior derecha para descargar)",
    "Export file format": "Formato de archivo de exportación",
    "Extra inference time": "Tiempo de inferencia adicional",
    "Extract": "Extraer",
    "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation": "Archivo de curva F0, opcional, un tono por línea, en lugar de F0 predeterminado y cambio de tono",
    "FAQ (Frequently Asked Questions)": "Preguntas frecuentes",
    "Fade length": "Duración del fundido de entrada/salida",
    "Fail": "Falló",
    "Feature extraction": "Extracción de características",
    "Formant offset": "Compensación resonante",
    "Fusion": "Fusión",
    "GPU Information": "información de la GPU",
    "General settings": "Configuración general",
    "Hidden": "Oculto",
    "ID of model A (long)": "ID del modelo A (largo)",
    "ID of model B (long)": "ID del modelo B (largo)",
    "ID(long)": "ID(long)",
    "ID(short)": "ID (corto)",
    "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.": "Si es >=3, entonces use el resultado del reconocimiento de tono de 'harvest' con filtro de mediana, el valor es el radio del filtro, su uso puede debilitar el sonido sordo",
    "Inference time (ms)": "Inferir tiempo (ms)",
    "Inferencing voice": "inferencia de voz",
    "Information": "Información",
    "Input device": "Dispositivo de entrada",
    "Input noise reduction": "Reducción de ruido de entrada",
    "Input voice monitor": "Monitor de voz de entrada",
    "Link index to outside folder": "Vincular índice a carpeta externa",
    "Load model": "Cargar modelo",
    "Load pre-trained base model D path": "Cargue la ruta del modelo D base pre-entrenada.",
    "Load pre-trained base model G path": "Cargue la ruta del modelo G base pre-entrenada.",
    "Loudness factor": "factor de sonoridad",
    "Model": "Modelo",
    "Model Author": "Autor del modelo",
    "Model Author (Nullable)": "Autor del modelo (anulable)",
    "Model Inference": "inferencia del modelo",
    "Model architecture version": "Versión y modelo del modelo",
    "Model info": "Información del modelo",
    "Model information to be modified": "Información del modelo a modificar",
    "Model information to be placed": "Información del modelo a colocar.",
    "Model name": "Nombre del modelo",
    "Modify": "Modificar",
    "Multiple audio files can also be imported. If a folder path exists, this input is ignored.": "También se pueden importar varios archivos de audio. Si existe una ruta de carpeta, esta entrada se ignora.",
    "No": "No",
    "None": "Ninguno",
    "Not exist": "Inexistente",
    "Number of CPU processes used for harvest pitch algorithm": "Número de procesos",
    "Number of CPU processes used for pitch extraction and data processing": "Número de procesos de CPU utilizados para extraer el tono y procesar los datos",
    "One-click training": "Entrenamiento con un clic",
    "Onnx Export Path": "Ruta de salida Onnx",
    "Output converted voice": "Salida de voz convertida",
    "Output device": "Dispositivo de salida",
    "Output information": "Información de salida",
    "Output noise reduction": "Reducción de ruido de salida",
    "Path to Model": "Ruta del modelo",
    "Path to Model A": "Modelo A ruta.",
    "Path to Model B": "Modelo B ruta.",
    "Path to the feature index file. Leave blank to use the selected result from the dropdown": "Ruta del archivo de la biblioteca de características, si está vacío, se utilizará el resultado de la selección desplegable",
    "Performance settings": "Configuración de rendimiento",
    "Pitch detection algorithm": "Algoritmo de tono",
    "Pitch guidance (f0)": "Guía de tono (f0)",
    "Pitch settings": "Ajuste de tono",
    "Please choose the .index file": "Seleccione el archivo .index",
    "Please choose the .pth file": "Seleccione el archivo .pth",
    "Please specify the speaker/singer ID": "ID del modelo",
    "Process data": "Procesar datos",
    "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy": "Proteger las consonantes claras y la respiración, prevenir artefactos como la distorsión de sonido electrónico, 0.5 no está activado, reducir aumentará la protección pero puede reducir el efecto del índice",
    "RVC Model Path": "Ruta del modelo RVC",
    "Read from model": "Leer del modelo",
    "Refresh voice list and index path": "Actualizar la lista de modelos e índice de rutas",
    "Reload device list": "Actualizar lista de dispositivos",
    "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling": "Remuestreo posterior al proceso a la tasa de muestreo final, 0 significa no remuestrear",
    "Response threshold": "Umbral de respuesta",
    "Sample length": "Longitud de muestreo",
    "Sampling rate": "Tasa de muestreo",
    "Save a small final model to the 'weights' folder at each save point": "Guardar pequeño modelo final en la carpeta 'weights' en cada punto de guardado",
    "Save file name (default: same as the source file)": "Nombre del archivo que se guardará, el valor predeterminado es el mismo que el nombre del archivo de origen",
    "Save frequency (save_every_epoch)": "Frecuencia de guardado (save_every_epoch)",
    "Save name": "Guardar nombre",
    "Save only the latest '.ckpt' file to save disk space": "Guardar solo el archivo ckpt más reciente para ahorrar espacio en disco",
    "Saved model name (without extension)": "Nombre del modelo guardado sin extensión.",
    "Sealing date": "fecha de sellado",
    "Search feature ratio (controls accent strength, too high has artifacting)": "Proporción de función de búsqueda",
    "Select Speaker/Singer ID": "Seleccione una identificación de altavoz",
    "Select the .index file": "Seleccione el archivo .index",
    "Select the .pth file": "Seleccione el archivo .pth",
    "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement": "Seleccione el algoritmo de extracción de tono, use 'pm' para acelerar la entrada de canto, 'harvest' es bueno para los graves pero extremadamente lento, 'crepe' tiene buenos resultados pero consume GPU",
    "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU": "Seleccione el algoritmo de extracción de tono: la canción de entrada se puede acelerar con pm, la voz de alta calidad pero CPU pobre se puede acelerar con dio, harvest es mejor pero más lento, rmvpe es el mejor y se come ligeramente la CPU/GPU",
    "Similarity": "Semejanza",
    "Similarity (from 0 to 1)": "Similitud (de 0 a 1)",
    "Single inference": "Inferencia única",
    "Specify output folder": "Especificar carpeta de salida",
    "Specify the output folder for accompaniment": "Especifique la carpeta de salida para las voces no principales",
    "Specify the output folder for vocals": "Especifique la carpeta de salida para la voz principal",
    "Start audio conversion": "Iniciar conversión de audio",
    "Step 1: Processing data": "Paso 1: Procesando datos",
    "Step 3a: Model training started": "Paso 3a: Entrenando el modelo",
    "Stop audio conversion": "Detener la conversión de audio",
    "Successfully built index into": "Índice construido con éxito en",
    "Takeover WASAPI device": "Adquisición del dispositivo WASAPI",
    "Target sample rate": "Tasa de muestreo objetivo",
    "The audio file to be processed": "El archivo de audio a procesar",
    "This software is open source under the MIT license. The author does not have any control over the software. Users who use the software and distribute the sounds exported by the software are solely responsible. <br>If you do not agree with this clause, you cannot use or reference any codes and files within the software package. See the root directory <b>Agreement-LICENSE.txt</b> for details.": "Este software es de código abierto bajo la licencia MIT, el autor no tiene ningún control sobre el software, y aquellos que usan el software y difunden los sonidos exportados por el software son los únicos responsables.<br>Si no está de acuerdo con esta cláusula , no puede utilizar ni citar ningún código ni archivo del paquete de software Consulte el directorio raíz <b>Agreement-LICENSE.txt</b> para obtener más información.",
    "Total training epochs (total_epoch)": "Total de épocas de entrenamiento (total_epoch)",
    "Train": "Entrenamiento",
    "Train feature index": "Índice de características",
    "Train model": "Entrenar Modelo",
    "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.": "Entrenamiento finalizado, puede ver el registro de entrenamiento en la consola o en el archivo train.log en la carpeta del experimento",
    "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)": "Cambio de tono (entero, número de semitonos, subir una octava +12 o bajar una octava -12)",
    "Unfortunately, there is no compatible GPU available to support your training.": "Lamentablemente, no tiene una tarjeta gráfica adecuada para soportar su entrenamiento",
    "Unknown": "Desconocido",
    "Unload model to save GPU memory": "Descargue la voz para ahorrar memoria GPU",
    "Version": "Versión",
    "View": "Ver",
    "Vocals/Accompaniment Separation & Reverberation Removal": "Separación de voz acompañante & eliminación de reverberación & eco",
    "Weight (w) for Model A": "Un peso modelo para el modelo A.",
    "Whether the model has pitch guidance": "Si el modelo tiene guía de tono.",
    "Whether the model has pitch guidance (1: yes, 0: no)": "Si el modelo tiene guía de tono, 1 para sí, 0 para no",
    "Whether the model has pitch guidance (required for singing, optional for speech)": "Si el modelo tiene guía de tono (necesaria para cantar, pero no para hablar)",
    "Yes": "Sí",
    "ckpt Processing": "Procesamiento de recibos",
    "index path cannot contain unicode characters": "La ruta del archivo .index no debe contener caracteres chinos.",
    "pth path cannot contain unicode characters": "La ruta del archivo .pth no debe contener caracteres chinos.",
    "step2:Pitch extraction & feature extraction": "Paso 2: Extracción del tono y extracción de características",
    "模型作者": "模型作者"
}
