{
    "### Model comparison\n> You can get model ID (long) from `View model information` below.\n\nCalculate a similarity between two models.": "### 模型比较\n> 模型ID(长)请于下方`查看模型信息`中获得\n\n可用于比较两模型推理相似度",
    "### Model extraction\n> Enter the path of the large file model under the 'logs' folder.\n\nThis is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model.": "### 模型提取\n> 输入logs文件夹下大文件模型路径\n\n适用于训一半不想训了模型没有自动提取保存小文件模型, 或者想测试中间模型的情况",
    "### Model fusion\nCan be used to test timbre fusion.": "### 模型融合\n可用于测试音色融合",
    "### Modify model information\n> Only supported for small model files extracted from the 'weights' folder.": "### 修改模型信息\n> 仅支持weights文件夹下提取的小模型文件",
    "### Step 1. Fill in the experimental configuration.\nExperimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.": "### 第一步 填写实验配置\n实验数据放在logs下, 每个实验一个文件夹, 需手工输入实验名路径, 内含实验配置, 日志, 训练得到的模型文件.",
    "### Step 2. Audio processing. \n#### 1. Slicing.\nAutomatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.": "### 第二步 音频处理\n#### 1. 音频切片\n自动遍历训练文件夹下所有可解码成音频的文件并进行切片归一化, 在实验目录下生成2个wav文件夹; 暂时只支持单人训练.",
    "### Step 3. Start training.\nFill in the training settings and start training the model and index.": "### 第三步 开始训练\n填写训练设置, 开始训练模型和索引.",
    "### View model information\n> Only supported for small model files extracted from the 'weights' folder.": "### 查看模型信息\n> 仅支持weights文件夹下提取的小模型文件",
    "#### 2. Feature extraction.\nUse CPU to extract pitch (if the model has pitch), use GPU to extract features (select GPU index).": "#### 2. 特征提取\n使用CPU提取音高(如果模型带音高), 使用GPU提取特征(选择卡号).",
    "Actually calculated": "实际计算",
    "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume": "输入源音量包络替换输出音量包络融合比例，越靠近1越使用输出包络",
    "Algorithmic delays (ms)": "算法延迟(ms)",
    "All processes have been completed!": "全流程结束！",
    "Audio device": "音频设备",
    "Auto-detect index path and select from the dropdown": "自动检测index路径,下拉式选择(dropdown)",
    "Batch conversion. Enter the folder containing the audio files to be converted or upload multiple audio files. The converted audio will be output in the specified folder (default: 'opt').": "批量转换, 输入待转换音频文件夹, 或上传多个音频文件, 在指定文件夹(默认opt)下输出转换的音频. ",
    "Batch inference": "批量推理",
    "Batch processing for vocal accompaniment separation using the UVR5 model.<br>Example of a valid folder path format: D:\\path\\to\\input\\folder (copy it from the file manager address bar).<br>The model is divided into three categories:<br>1. Preserve vocals: Choose this option for audio without harmonies. It preserves vocals better than HP5. It includes two built-in models: HP2 and HP3. HP3 may slightly leak accompaniment but preserves vocals slightly better than HP2.<br>2. Preserve main vocals only: Choose this option for audio with harmonies. It may weaken the main vocals. It includes one built-in model: HP5.<br>3. De-reverb and de-delay models (by FoxJoy):<br>  (1) MDX-Net: The best choice for stereo reverb removal but cannot remove mono reverb;<br>&emsp;(234) DeEcho: Removes delay effects. Aggressive mode removes more thoroughly than Normal mode. DeReverb additionally removes reverb and can remove mono reverb, but not very effectively for heavily reverberated high-frequency content.<br>De-reverb/de-delay notes:<br>1. The processing time for the DeEcho-DeReverb model is approximately twice as long as the other two DeEcho models.<br>2. The MDX-Net-Dereverb model is quite slow.<br>3. The recommended cleanest configuration is to apply MDX-Net first and then DeEcho-Aggressive.": "人声伴奏分离批量处理， 使用UVR5模型。 <br>合格的文件夹路径格式举例： E:\\codes\\py39\\vits_vc_gpu\\白鹭霜华测试样例(去文件管理器地址栏拷就行了)。 <br>模型分为三类： <br>1、保留人声：不带和声的音频选这个，对主人声保留比HP5更好。内置HP2和HP3两个模型，HP3可能轻微漏伴奏但对主人声保留比HP2稍微好一丁点； <br>2、仅保留主人声：带和声的音频选这个，对主人声可能有削弱。内置HP5一个模型； <br> 3、去混响、去延迟模型（by FoxJoy）：<br>  (1)MDX-Net(onnx_dereverb):对于双通道混响是最好的选择，不能去除单通道混响；<br>&emsp;(234)DeEcho:去除延迟效果。Aggressive比Normal去除得更彻底，DeReverb额外去除混响，可去除单声道混响，但是对高频重的板式混响去不干净。<br>去混响/去延迟，附：<br>1、DeEcho-DeReverb模型的耗时是另外2个DeEcho模型的接近2倍；<br>2、MDX-Net-Dereverb模型挺慢的；<br>3、个人推荐的最干净的配置是先MDX-Net再DeEcho-Aggressive。",
    "Batch size per GPU": "每张显卡的batch_size",
    "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement": "是否缓存所有训练集至显存. 10min以下小数据可缓存以加速训练, 大数据缓存会炸显存也加不了多少速",
    "Calculate": "计算",
    "Choose sample rate of the device": "使用设备采样率",
    "Choose sample rate of the model": "使用模型采样率",
    "Convert": "转换",
    "Device type": "设备类型",
    "Enable phase vocoder": "启用相位声码器",
    "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2": "以-分隔输入使用的卡号, 例如   0-1-2   使用卡0和卡1和卡2",
    "Enter the experiment name": "输入实验名",
    "Enter the path of the audio folder to be processed": "输入待处理音频文件夹路径",
    "Enter the path of the audio folder to be processed (copy it from the address bar of the file manager)": "输入待处理音频文件夹路径(去文件管理器地址栏拷就行了)",
    "Enter the path of the training folder": "输入训练文件夹路径",
    "Exist": "有",
    "Export Onnx": "Onnx导出",
    "Export Onnx Model": "导出Onnx模型",
    "Export audio (click on the three dots in the lower right corner to download)": "输出音频(右下角三个点,点了可以下载)",
    "Export file format": "导出文件格式",
    "Extra inference time": "额外推理时长",
    "Extract": "提取",
    "F0 curve file (optional). One pitch per line. Replaces the default F0 and pitch modulation": "F0曲线文件, 可选, 一行一个音高, 代替默认F0及升降调",
    "FAQ (Frequently Asked Questions)": "常见问题解答",
    "Fade length": "淡入淡出长度",
    "Fail": "失败",
    "Feature extraction": "特征提取",
    "Feature searching ratio": "检索特征占比",
    "Formant offset": "共振偏移",
    "Fusion": "融合",
    "GPU Information": "显卡信息",
    "General settings": "常规设置",
    "Hidden": "不显示",
    "ID of model A (long)": "A模型ID(长)",
    "ID of model B (long)": "B模型ID(长)",
    "ID(long)": "ID(long)",
    "ID(short)": "ID(短)",
    "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.": ">=3则使用对harvest音高识别的结果使用中值滤波，数值为滤波半径，使用可以削弱哑音",
    "Inference time (ms)": "推理时间(ms)",
    "Inferencing voice": "推理音色",
    "Information": "信息",
    "Input device": "输入设备",
    "Input noise reduction": "输入降噪",
    "Input voice monitor": "输入监听",
    "Link index to outside folder": "链接索引到外部",
    "Load model": "加载模型",
    "Load pre-trained base model D path": "加载预训练底模D路径",
    "Load pre-trained base model G path": "加载预训练底模G路径",
    "Loudness factor": "响度因子",
    "Model": "模型",
    "Model Author": "模型作者",
    "Model Author (Nullable)": "模型作者(可空)",
    "Model Inference": "模型推理",
    "Model architecture version": "模型版本型号",
    "Model info": "模型信息",
    "Model information to be modified": "要改的模型信息",
    "Model information to be placed": "要置入的模型信息",
    "Model name": "模型名",
    "Modify": "修改",
    "Multiple audio files can also be imported. If a folder path exists, this input is ignored.": "也可批量输入音频文件, 二选一, 优先读文件夹",
    "No": "否",
    "None": "空",
    "Not exist": "无",
    "Number of CPU processes used for harvest pitch algorithm": "harvest进程数",
    "Number of CPU processes used for pitch extraction and data processing": "提取音高和处理数据使用的CPU进程数",
    "One-click training": "一键训练",
    "Onnx Export Path": "Onnx输出路径",
    "Output converted voice": "输出变声",
    "Output device": "输出设备",
    "Output information": "输出信息",
    "Output noise reduction": "输出降噪",
    "Path to Model": "模型路径",
    "Path to Model A": "A模型路径",
    "Path to Model B": "B模型路径",
    "Path to the feature index file. Leave blank to use the selected result from the dropdown": "特征检索库文件路径,为空则使用下拉的选择结果",
    "Performance settings": "性能设置",
    "Pitch detection algorithm": "音高算法",
    "Pitch guidance (f0)": "音高引导(f0)",
    "Pitch settings": "音调设置",
    "Please choose the .index file": "请选择index文件",
    "Please choose the .pth file": "请选择pth文件",
    "Please specify the speaker/singer ID": "请指定说话人id",
    "Process data": "处理数据",
    "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy": "保护清辅音和呼吸声，防止电音撕裂等artifact，拉满0.5不开启，调低加大保护力度但可能降低索引效果",
    "RVC Model Path": "RVC模型路径",
    "Read from model": "从模型中读取",
    "Refresh voice list and index path": "刷新音色列表和索引路径",
    "Reload device list": "重载设备列表",
    "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling": "后处理重采样至最终采样率，0为不进行重采样",
    "Response threshold": "响应阈值",
    "Sample length": "采样长度",
    "Sampling rate": "采样率",
    "Save a small final model to the 'weights' folder at each save point": "是否在每次保存时间点将最终小模型保存至weights文件夹",
    "Save file name (default: same as the source file)": "保存的文件名, 默认空为和源文件同名",
    "Save frequency (save_every_epoch)": "保存频率save_every_epoch",
    "Save name": "保存名",
    "Save only the latest '.ckpt' file to save disk space": "是否仅保存最新的ckpt文件以节省硬盘空间",
    "Saved model name (without extension)": "保存的模型名不带后缀",
    "Sealing date": "封装时间",
    "Select Speaker/Singer ID": "请选择说话人id",
    "Select the .index file": "选择.index文件",
    "Select the .pth file": "选择.pth文件",
    "Select the pitch extraction algorithm ('pm': faster extraction but lower-quality speech; 'harvest': better bass but extremely slow; 'crepe': better quality but GPU intensive), 'rmvpe': best quality, and little GPU requirement": "选择音高提取算法,输入歌声可用pm提速,harvest低音好但巨慢无比,crepe效果好但吃GPU,rmvpe效果最好且微吃GPU",
    "Select the pitch extraction algorithm: when extracting singing, you can use 'pm' to speed up. For high-quality speech with fast performance, but worse CPU usage, you can use 'dio'. 'harvest' results in better quality but is slower.  'rmvpe' has the best results and consumes less CPU/GPU": "选择音高提取算法:输入歌声可用pm提速,高质量语音但CPU差可用dio提速,harvest质量更好但慢,rmvpe效果最好且微吃CPU/GPU",
    "Similarity": "相似度",
    "Similarity (from 0 to 1)": "相似度(0到1)",
    "Single inference": "单次推理",
    "Specify output folder": "指定输出文件夹",
    "Specify the output folder for accompaniment": "指定输出非主人声文件夹",
    "Specify the output folder for vocals": "指定输出主人声文件夹",
    "Start audio conversion": "开始音频转换",
    "Step 1: Processing data": "step1:正在处理数据",
    "Step 3a: Model training started": "step3a:正在训练模型",
    "Stop audio conversion": "停止音频转换",
    "Successfully built index into": "成功构建索引到",
    "Takeover WASAPI device": "独占 WASAPI 设备",
    "Target sample rate": "目标采样率",
    "The audio file to be processed": "待处理音频文件",
    "This software is licensed under the GNU Affero General Public License, version 3.0 or later.<br>The author has no control or responsibility regarding the use of this software.<br>Users who use the software and distribute any content, including sounds or files generated by it, bear full responsibility for compliance with the terms of the AGPL 3.0 license.<br>If you do not accept these terms, you are prohibited from using, referencing, or distributing any code or files contained within this software package.<br>Refer to the LICENSE file located in the root directory for full details.": "This software is licensed under the GNU Affero General Public License, version 3.0 or later.<br>The author has no control or responsibility regarding the use of this software.<br>Users who use the software and distribute any content, including sounds or files generated by it, bear full responsibility for compliance with the terms of the AGPL 3.0 license.<br>If you do not accept these terms, you are prohibited from using, referencing, or distributing any code or files contained within this software package.<br>Refer to the LICENSE file located in the root directory for full details.",
    "Total training epochs (total_epoch)": "总训练轮数total_epoch",
    "Train": "训练",
    "Train feature index": "训练特征索引",
    "Train model": "训练模型",
    "Training complete. You can check the training logs in the console or the 'train.log' file under the experiment folder.": "训练结束, 您可查看控制台训练日志或实验文件夹下的train.log",
    "Transpose (integer, number of semitones, raise by an octave: 12, lower by an octave: -12)": "变调(整数, 半音数量, 升八度12降八度-12)",
    "Unknown": "未知",
    "Unload model to save GPU memory": "卸载音色省显存",
    "Version": "版本",
    "View": "查看",
    "Vocals/Accompaniment Separation & Reverberation Removal": "伴奏人声分离&去混响&去回声",
    "Weight (w) for Model A": "A模型权重",
    "Whether the model has pitch guidance": "模型是否带音高指导",
    "Whether the model has pitch guidance (1: yes, 0: no)": "模型是否带音高指导,1是0否",
    "Whether the model has pitch guidance (required for singing, optional for speech)": "模型是否带音高指导(唱歌一定要, 语音可以不要)",
    "Yes": "是",
    "ckpt Processing": "ckpt处理",
    "index path cannot contain unicode characters": "index文件路径不可包含中文",
    "pth path cannot contain unicode characters": "pth文件路径不可包含中文",
    "step2:Pitch extraction & feature extraction": "step2:正在提取音高&正在提取特征"
}
